<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deci Research</title>
  <link rel="icon" href="images/favicon/deci.png" type="image/png">
  <link rel="stylesheet" href="assets/css/styles.css">
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <div class="brand">Deci Research</div>
      <nav class="nav">
        <a href="#home">Home</a>
        <a href="#team">Team</a>
        <a href="#publications">Publications</a>
      </nav>
    </div>
  </header>

  <main>
    <section id="home" class="section hero">
      <div class="container hero-inner">
        <div class="hero-text">
          <h1>Welcome to the Deci Research website.</h1>
          <p class="lead" id="welcome-copy">
            Welcome to the Deci/Research team at NVIDIA, led by Prof. Ran El‑Yaniv. Deci/Research is part of the NVIDIA Deci group, led by Dr. Yonatan Geifman.
          </p>
          <p class="lead">
            Our mission is to improve inference efficiency in advanced AI, with a focus on large language models. We co design model architecture, inference schemes (such as thinking and deep research) and the deployment stack, using methods such as NAS to improve utility (e.g., latency reduction, throughput maximization) while preserving quality, with solutions optimized for NVIDIA GPUs for real world inference scenarios.
          </p>
          <p class="lead">
            We are deep learning research engineers, and scientists with broad and deep experience in every aspect of AI models. Our backgrounds span architecture design, data and training pipelines, optimization and compression, hardware aware implementation, rigorous evaluation, and reliable production serving at scale.
          </p>
          <p class="lead">
            Deci/Research was Founded in 2020 within Deci AI (acquired by NVIDIA in 2024).
          </p>
        </div>
        <div class="hero-visual">
          <img src="images/brand/nvidia_logo.png" alt="NVIDIA logo">
        </div>
      </div>
    </section>

    <section id="team" class="section">
      <div class="container">
        <h2>Team</h2>
        <div class="team-grid">
          <!-- Sorted by last name (A–Z) -->
          <div class="member-card">
            <img src="images/team/nir_ailon.png" alt="Nir Ailon">
            <div class="member-info">
              <div class="member-name">Nir Ailon</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=MpckH9YAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/nir-ailon/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/vladimir_anisimov.png" alt="Vladimir Anisimov">
            <div class="member-info">
              <div class="member-name">Vladimir Anisimov</div>
              <div class="member-links">
                <a href="https://www.linkedin.com/in/vova-anisimov/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/akhiad_bercovich.png" alt="Akhiad Bercovich">
            <div class="member-info">
              <div class="member-name">Akhiad Bercovich</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=iOq6BhIAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/akhiad-bercovich-9b5709112/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/mohammad_dabbah.png" alt="Mohammad Dabbah">
            <div class="member-info">
              <div class="member-name">Mohammad Dabbah</div>
              <div class="member-links">
                <a href="https://www.semanticscholar.org/author/Mohammed-Dabbah/2142398307" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/mohammed-dabbah-0b375a143/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/ran_el-yaniv.jpg" alt="Ran El-Yaniv">
            <div class="member-info">
              <div class="member-name">Ran El-Yaniv</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=D9eVSd8AAAAJ&hl=en" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/ran-el-yaniv-33a5b22/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/ido_galil.jfif" alt="Ido Galil">
            <div class="member-info">
              <div class="member-name">Ido Galil</div>
              <div class="member-links">
                <a href="https://idogalil.github.io/" target="_blank" rel="noopener">Website</a>
                <a href="https://scholar.google.com/citations?user=eZA2cu8AAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/ido-galil/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/amnon_geifman.png" alt="Amnon Geifman">
            <div class="member-info">
              <div class="member-name">Amnon Geifman</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=Drcgf9wAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/amnongeifman/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/izik_golan.png" alt="Izik Golan">
            <div class="member-info">
              <div class="member-name">Izik Golan</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=byL3mIkAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/izik-golan-94828298/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/itay_levy.png" alt="Itay Levy">
            <div class="member-info">
              <div class="member-name">Itay Levy</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=fcEmFdEAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/itay-levy-cs/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/zach_moshe.png" alt="Zach Moshe">
            <div class="member-info">
              <div class="member-name">Zach Moshe</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=aVMJjXAAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/zachmoshe/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/najeeb_nabwani.png" alt="Najeeb Nabwani">
            <div class="member-info">
              <div class="member-name">Najeeb Nabwani</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=vLgn-WsAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/najeeb-n-18846b165/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/omri_puny.png" alt="Omri Puny">
            <div class="member-info">
              <div class="member-name">Omri Puny</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=7GXWu34AAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/omri-puny-0917771b2/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/tomer_ronen.png" alt="Tomer Ronen">
            <div class="member-info">
              <div class="member-name">Tomer Ronen</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=QMKtNIUAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/tomerronen/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/itamar_schen.png" alt="Itamar Schen">
            <div class="member-info">
              <div class="member-name">Itamar Schen</div>
              <div class="member-links">
                <a href="https://www.linkedin.com/in/itamar-schen/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/elad_segal.png" alt="Elad Segal">
            <div class="member-info">
              <div class="member-name">Elad Segal</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=0ECOF7cAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/eladsegal/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/ido_shahaf.png" alt="Ido Shahaf">
            <div class="member-info">
              <div class="member-name">Ido Shahaf</div>
              <div class="member-links">
                <a href="https://scholar.google.co.il/citations?user=eGS4sGwAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Scholar</a>
                <a href="https://www.linkedin.com/in/ido-shahaf/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
          <div class="member-card">
            <img src="images/team/oren_tropp.png" alt="Oren Tropp">
            <div class="member-info">
              <div class="member-name">Oren Tropp</div>
              <div class="member-links">
                <a href="https://www.linkedin.com/in/oren-tropp-a3506318/" target="_blank" rel="noopener">LinkedIn</a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="publications" class="section alt">
      <div class="container">
        <h2>Publications</h2>
        <div class="pub-list">
          <!-- Newest first: FFN Fusion, Llama‑Nemotron, Puzzle -->
          <article class="pub-card">
            <div class="pub-media">
              <img class="pub-thumb" src="images/papers/ffn_fusion.jpg" alt="FFN Fusion">
            </div>
            <div class="pub-body">
              <h3>FFN Fusion: Rethinking Sequential Computation in Large Language Models</h3>
              <p class="pub-meta">
                <img class="venue-logo" src="images/venues/neurips_logo.png" alt="NeurIPS"> NeurIPS, 2025 (Spotlight)
              </p>
              <p class="pub-meta"><strong>TL;DR</strong>: FFN Fusion fuses consecutive FFN layers into larger blocks, reducing sequential depth and accelerating inference with minimal accuracy impact.</p>
              <div class="pub-links">
                <a href="https://arxiv.org/pdf/2503.18908v1" target="_blank" rel="noopener">Paper</a>
                <a href="#" data-toggle="#ffn-details">Read more</a>
              </div>
              <div id="ffn-details" class="pub-details" aria-expanded="false">
                <p>
                  We run Puzzle to search hardware‑aware designs, then fuse consecutive FFNs into larger FFNs, decreasing the model's depth. Across models from tens to hundreds of billions of parameters, FFN Fusion reduces latency and cost while preserving quality, and complements techniques such as quantization and pruning.
                </p>
                <p>
                  Authors: Akhiad Bercovich · Mohammad Dabbah · Omri Puny · Ido Galil · Amnon Geifman · Yonatan Geifman · Izhak Golan · Ehud Karpas · Itay Levy · Zach Moshe · Najeeb Nabwani · Tomer Ronen · Itamar Schen · Elad Segal · Ido Shahaf · Oren Tropp · Ran Zilberstein · Ran El-Yaniv
                </p>
              </div>
            </div>
          </article>
          <article class="pub-card">
            <div class="pub-media">
              <img class="pub-thumb" src="images/papers/llama_nemotron.jpg" alt="Llama-Nemotron">
            </div>
            <div class="pub-body">
              <h3>Llama-Nemotron: Efficient Reasoning Models</h3>
              <p class="pub-meta">
                <img class="venue-logo" src="images/venues/ICML-logo.svg" alt="ICML"> ICML, 2025 - EXAIT Workshop
              </p>
              <p class="pub-meta"><strong>TL;DR</strong>: Llama‑Nemotron is a family of open reasoning LLMs (8B/49B/253B) that match state‑of‑the‑art reasoning quality while significantly improving inference throughput and memory efficiency, and include a dynamic reasoning toggle for controllable compute.</p>
              <div class="pub-links">
                <a href="https://arxiv.org/abs/2505.00949" target="_blank" rel="noopener">Paper</a>
                <a href="#" data-toggle="#nemotron-details">Read more</a>
              </div>
              <div id="nemotron-details" class="pub-details" aria-expanded="false">
                <p>
                  Llama‑Nemotron introduces heterogeneous reasoning models trained for both quality and efficiency. The recipe combines architecture search from Llama‑3 for faster inference, knowledge distillation and continued pretraining, followed by a reasoning‑focused post‑training stage (supervised fine‑tuning and large‑scale RL). The family (Nano 8B, Super 49B, Ultra 253B) achieves competitive reasoning vs. leading systems while improving throughput and memory use, and supports switching between standard chat and reasoning modes at inference time. The release includes models, a post‑training dataset, and training codebases (<a href="https://github.com/NVIDIA/NeMo" target="_blank" rel="noopener">NeMo</a>, <a href="https://github.com/NVIDIA/NeMo-Aligner" target="_blank" rel="noopener">NeMo‑Aligner</a>, <a href="https://github.com/NVIDIA/Megatron-LM" target="_blank" rel="noopener">Megatron‑LM</a>).
                </p>
                <p>
                  Authors: Akhiad Bercovich · Itay Levy · Izik Golan · Mohammad Dabbah · Ran El-Yaniv · Omri Puny · Ido Galil · Zach Moshe · Tomer Ronen · Najeeb Nabwani · Ido Shahaf · Oren Tropp · Ehud Karpas · Ran Zilberstein · Jiaqi Zeng · Soumye Singhal · Alexander Bukharin · Yian Zhang · Tugrul Konuk · Gerald Shen · Ameya Sunil Mahabaleshwarkar · Bilal Kartal · Yoshi Suhara · Olivier Delalleau · Zijia Chen · Zhilin Wang · David Mosallanezhad · Adi Renduchintala · Haifeng Qian · Dima Rekesh · Fei Jia · Somshubra Majumdar · Vahid Noroozi · Wasi Uddin Ahmad · Sean Narenthiran · Aleksander Ficek · Mehrzad Samadi · Jocelyn Huang · Siddhartha Jain · Igor Gitman · Ivan Moshkov · Wei Du · Shubham Toshniwal · George Armstrong · Branislav Kisacanin · Matvei Novikov · Daria Gitman · Evelina Bakhturina · Prasoon Varshney · Makesh Narsimhan · Jane Polak Scowcroft · John Kamalu · Dan Su · Kezhi Kong · Markus Kliegl · Rabeeh Karimi Mahabadi · Ying Lin · Sanjeev Satheesh · Jupinder Parmar · Pritam Gundecha · Brandon Norick · Joseph Jennings · Shrimai Prabhumoye · Syeda Nahida Akter · Mostofa Patwary · Abhinav Khattar · Deepak Narayanan · Roger Waleffe · Jimmy Zhang · Bor-Yiing Su · Guyue Huang · Terry Kong · Parth Chadha · Sahil Jain · Christine Harvey · Elad Segal · Jining Huang · Sergey Kashirsky · Robert McQueen · Izzy Putterman · George Lam · Arun Venkatesan · Sherry Wu · Vinh Nguyen · Manoj Kilaru · Andrew Wang · Anna Warno · Abhilash Somasamudramath · Sandip Bhaskar · Maka Dong · Nave Assaf · Shahar Mor · Omer Ullman Argov · Scot Junkin · Oleksandr Romanenko · Pedro Larroy · Monika Katariya · Marco Rovinelli · Viji Balas · Nicholas Edelman · Anahita Bhiwandiwalla · Muthu Subramaniam · Smita Ithape · Karthik Ramamoorthy · Yuting Wu · Suguna Varshini Velury · Omri Almog · Joyjit Daw · Denys Fridman · Erick Galinkin · Michael Evans · Shaona Ghosh · Katherine Luna · Leon Derczynski · Nikki Pope · Eileen Long · Seth Schneider · Guillermo Siman · Tomasz Grzegorzek · Pablo Ribalta · Monika Katariya · Chris Alexiuk · Joey Conway · Trisha Saar · Ann Guan · Krzysztof Pawelec · Shyamala Prayaga · Oleksii Kuchaiev · Boris Ginsburg · Oluwatobi Olabiyi · Kari Briski · Jonathan Cohen · Bryan Catanzaro · Jonah Alben · Yonatan Geifman · Eric Chung
                </p>
              </div>
            </div>
          </article>
          <article class="pub-card">
            <div class="pub-media">
              <img class="pub-thumb" src="images/papers/puzzle_overview.png" alt="Puzzle overview">
            </div>
            <div class="pub-body">
              <h3>Puzzle: Distillation-Based NAS for Inference-Optimized LLMs</h3>
              <p class="pub-meta">
                <img class="venue-logo" src="images/venues/ICML-logo.svg" alt="ICML"> ICML, 2025
              </p>
              <p class="pub-meta"><strong>TL;DR</strong>: Puzzle accelerates LLM inference on specific hardware by leveraging blockwise local knowledge distillation and mixed-integer programming to preserve model performance while significantly reducing inference costs.</p>
              <div class="pub-links">
                <a href="https://openreview.net/pdf?id=RY5MMBHRqo" target="_blank" rel="noopener">Paper</a>
                <a href="https://www.youtube.com/watch?v=YsIv9Kr99C4" target="_blank" rel="noopener">Video</a>
                <a href="https://github.com/NVlabs/puzzle" target="_blank" rel="noopener">Code</a>
                <a href="#" data-toggle="#puzzle-details">Read more</a>
              </div>
              <div id="puzzle-details" class="pub-details" aria-expanded="false">
                <p>
                  Despite LLMs’ impressive results, they are often limited by computational costs during inference. Puzzle addresses this by optimizing large-scale models for specific hardware without sacrificing accuracy, resulting in up to 2.17× speedups.
                </p>
                <p>
                  Authors: Akhiad Bercovich · Tomer Ronen · Talor Abramovich · Nir Ailon · Nave Assaf · Mohammad Dabbah · Ido Galil · Amnon Geifman · Yonatan Geifman · Izhak Golan · Netanel Haber · Ehud Karpas · Roi Koren · Itay Levy · Pavlo Molchanov · Shahar Mor · Zach Moshe · Najeeb Nabwani · Omri Puny · Ran Rubin · Itamar Schen · Ido Shahaf · Oren Tropp · Omer Ullman Argov · Ran Zilberstein · Ran El-Yaniv
                </p>
              </div>
            </div>
          </article>
        </div>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container">
      © <span id="year"></span> Deci Research, NVIDIA
    </div>
  </footer>

  <script src="assets/js/main.js"></script>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>
</html>


